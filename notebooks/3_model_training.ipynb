{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c33a879",
   "metadata": {},
   "source": [
    "This notebook is only for training the models with the best parametrs found in `3_model_training`. If you don't need the trained models, you can skip to `4_evaluation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e2af455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "os.sys.path.append(os.path.abspath('../src'))\n",
    "from data import preprocessor\n",
    "\n",
    "mapname = 'Town01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dc66672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_train_model(model, args):\n",
    "    \"\"\"\n",
    "    Function to create and train a model with given parameters.\n",
    "\n",
    "    Args:\n",
    "        model: The model to be trained.\n",
    "        args: Arguments for training the model.\n",
    "\n",
    "    Returns:\n",
    "        result: The result of the training process.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    # Train model with current hyperparameters\n",
    "    md = model(**args)\n",
    "    md.fit(X_train, y_train)\n",
    "    # Predict on the validation set\n",
    "    y_pred = md.predict(X_val)\n",
    "    # Log training results\n",
    "    result[\"f1_score\"] = f1_score(y_val, y_pred, average='weighted')\n",
    "    result[\"accuracy\"] = accuracy_score(y_val, y_pred)\n",
    "    result[\"recall\"] = recall_score(y_val, y_pred, average='weighted')\n",
    "    result[\"precision\"] = precision_score(y_val, y_pred, average='weighted')\n",
    "    result[\"model\"] = md\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67b3bdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_dict(dict, key, model, results, params):\n",
    "    \"\"\"\n",
    "    Function to add results to the dictionary.\n",
    "\n",
    "    Args:\n",
    "        dict: The dictionary to which results will be added.\n",
    "        key: The key for the dictionary.\n",
    "        model: The model used.\n",
    "        results: The results of the training process.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if key not in dict:\n",
    "        dict[key] = {\n",
    "            'model': model,\n",
    "            'params': params,\n",
    "            'f1_scores': [],\n",
    "            'accuracy': [],\n",
    "            'recall': [],\n",
    "            'precision': [],\n",
    "        }\n",
    "    \n",
    "    dict[key]['f1_scores'].append(results['f1_score'])\n",
    "    dict[key]['accuracy'].append(results['accuracy'])\n",
    "    dict[key]['recall'].append(results['recall'])\n",
    "    dict[key]['precision'].append(results['precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14359ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results_to_csv(dict, filename, metrics_path = '../results/metrics/'):\n",
    "    \"\"\" Function to save results to a CSV file. \n",
    "    Args:\n",
    "        dict: The dictionary containing results.\n",
    "        filename: The name of the file to save results.\n",
    "        metrics_path: The path where the file will be saved.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    with open(f'{metrics_path}/{filename}_results.csv', 'w', newline='') as csvfile:\n",
    "        fieldnames = ['key', 'model', 'f1_score_mean', 'f1_score_std', 'accuracy_mean', 'accuracy_std', 'recall_mean', 'recall_std', 'precision_mean', 'precision_std', 'params']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for key, value in dict.items():\n",
    "            writer.writerow({\n",
    "                'key': key,\n",
    "                'model': value['model'],\n",
    "                'f1_score_mean': np.mean(value['f1_scores']),\n",
    "                'f1_score_std': np.std(value['f1_scores']),\n",
    "                'accuracy_mean': np.mean(value['accuracy']),\n",
    "                'accuracy_std': np.std(value['accuracy']),\n",
    "                'recall_mean': np.mean(value['recall']),\n",
    "                'recall_std': np.std(value['recall']),\n",
    "                'precision_mean': np.mean(value['precision']),\n",
    "                'precision_std': np.std(value['precision']),\n",
    "                'params': value['params']\n",
    "            })\n",
    "\n",
    "    dict_means = {}\n",
    "    for key, value in dict.items():\n",
    "        dict_means[key] = {\n",
    "            'f1_score': np.mean(value['f1_scores']),\n",
    "            'accuracy': np.mean(value['accuracy']),\n",
    "            'recall': np.mean(value['recall']),\n",
    "            'precision': np.mean(value['precision']),\n",
    "            'model': value['model'],\n",
    "            'params': value['params']\n",
    "        }\n",
    "\n",
    "    dict_means_df = pd.DataFrame.from_dict(dict_means, orient='index').sort_values(by='f1_score', ascending=False)\n",
    "    dict_means_df.index.name = 'key'\n",
    "    dict_means_df.to_csv(f'{metrics_path}/{filename}_means.csv')\n",
    "    print(dict_means_df, end='\\n\\n')\n",
    "\n",
    "    for key, value in dict.items():\n",
    "        print(f\"{key}:\")\n",
    "        print(f\"  Model: {value['model']}\")\n",
    "        print(f\"  F1 Score: {np.mean(value['f1_scores']):.2f} ± {np.std(value['f1_scores']):.2f}\")\n",
    "        print(f\"  Accuracy: {np.mean(value['accuracy']):.2f} ± {np.std(value['accuracy']):.2f}\")\n",
    "        print(f\"  Recall: {np.mean(value['recall']):.2f} ± {np.std(value['recall']):.2f}\")\n",
    "        print(f\"  Precision: {np.mean(value['precision']):.2f} ± {np.std(value['precision']):.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7abae7f",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bb894a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data'\n",
    "uah_training = pd.read_csv(f'{data_path}/base/training_set_uah.csv')\n",
    "uah_validation = pd.read_csv(f'{data_path}/base/validation_set_uah.csv')\n",
    "\n",
    "carla_fixed = pd.read_csv(f'{data_path}/merged/{mapname}/carla/carla_fixed.csv').drop(columns=['origin'])\n",
    "carla_llm = pd.read_csv(f'{data_path}/merged/{mapname}/carla/carla_llm.csv').drop(columns=['origin'])\n",
    "\n",
    "sumo_fixed = pd.read_csv(f'{data_path}/merged/{mapname}/sumo/sumo_fixed.csv').drop(columns=['origin'])\n",
    "sumo_llm = pd.read_csv(f'{data_path}/merged/{mapname}/sumo/sumo_llm.csv').drop(columns=['origin'])\n",
    "\n",
    "carla_uah_fixed = pd.read_csv(f'{data_path}/merged/{mapname}/carla_uah/carla_uah_fixed.csv')\n",
    "carla_uah_llm = pd.read_csv(f'{data_path}/merged/{mapname}/carla_uah/carla_uah_llm.csv')\n",
    "\n",
    "sumo_uah_fixed = pd.read_csv(f'{data_path}/merged/{mapname}/sumo_uah/sumo_uah_fixed.csv')\n",
    "sumo_uah_llm = pd.read_csv(f'{data_path}/merged/{mapname}/sumo_uah/sumo_uah_llm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95fa01a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMO features: ['acc', 'angle', 'speed', 'label']\n",
      "CARLA features: ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z', 'angle', 'label', 'acc']\n"
     ]
    }
   ],
   "source": [
    "sumo_columns_to_keep = sumo_fixed.columns.tolist()\n",
    "carla_columns_to_keep = carla_fixed.columns.tolist()\n",
    "print(\"SUMO features:\", sumo_columns_to_keep)\n",
    "print(\"CARLA features:\", carla_columns_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b2b12e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 10\n",
    "step_size = 5\n",
    "one_hot_keys = {\n",
    "    'normal': 0,\n",
    "    'aggressive': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bfe165",
   "metadata": {},
   "source": [
    "# Train on Real test on Synthetic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b177f276",
   "metadata": {},
   "source": [
    "By training a model on real data and testing on synthetic data, we verify synthetic data’s fidelity with the real-world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b866bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRTS = {}\n",
    "n_trials = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b448fee4",
   "metadata": {},
   "source": [
    "## SUMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "648199c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = preprocessor.sliding_windows(uah_training[sumo_columns_to_keep], window_size=10, step_size=5)\n",
    "y_train = preprocessor.one_hot_encode(y_train, one_hot_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e8a837",
   "metadata": {},
   "source": [
    "### Fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "454ba591",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, y_val = preprocessor.sliding_windows(sumo_fixed, window_size=10, step_size=5)\n",
    "y_val = preprocessor.one_hot_encode(y_val, one_hot_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5eefdc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model: XGBClassifier_{'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 200, 'subsample': 0.7}\n",
    "params = {\n",
    "    'colsample_bytree': 0.5,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': None,\n",
    "    'n_estimators': 200,\n",
    "    'subsample': 0.7,\n",
    "}\n",
    "for i in range(n_trials):\n",
    "    results = create_and_train_model(xgb.XGBClassifier, params)\n",
    "    add_to_dict(TRTS, 'sumo_fixed', 'XGBClassifier', results, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e89ace",
   "metadata": {},
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a56d8a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, y_val = preprocessor.sliding_windows(sumo_llm, window_size=10, step_size=5)\n",
    "y_val = preprocessor.one_hot_encode(y_val, one_hot_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6347cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model: XGBClassifier_{'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 1000, 'subsample': 0.7}\n",
    "params = {\n",
    "    'colsample_bytree': 1.0,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': None,\n",
    "    'n_estimators': 1000,\n",
    "    'subsample': 0.7,\n",
    "}\n",
    "for i in range(n_trials):\n",
    "    results = create_and_train_model(xgb.XGBClassifier, params)\n",
    "    add_to_dict(TRTS, 'sumo_llm', 'XGBClassifier', results, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7034dab6",
   "metadata": {},
   "source": [
    "## CARLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79611d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = preprocessor.sliding_windows(uah_training[carla_columns_to_keep], window_size=10, step_size=5)\n",
    "y_train = preprocessor.one_hot_encode(y_train, one_hot_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe814c3",
   "metadata": {},
   "source": [
    "### Fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61938828",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, y_val = preprocessor.sliding_windows(carla_fixed, window_size=10, step_size=5)\n",
    "y_val = preprocessor.one_hot_encode(y_val, one_hot_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a441564d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renan/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/renan/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/renan/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/renan/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/renan/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/renan/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/renan/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/renan/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Best model: XGBClassifier_{'colsample_bytree': 1.0, 'learning_rate': 0.001, 'max_depth': 5, 'n_estimators': 200, 'subsample': 0.7}\n",
    "params = {\n",
    "    'colsample_bytree': 1.0,\n",
    "    'learning_rate': 0.001,\n",
    "    'max_depth': 5,\n",
    "    'n_estimators': 200,\n",
    "    'subsample': 0.7,\n",
    "}\n",
    "for i in range(n_trials):\n",
    "    results = create_and_train_model(xgb.XGBClassifier, params)\n",
    "    add_to_dict(TRTS, 'carla_fixed', 'XGBClassifier', results, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67747de7",
   "metadata": {},
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3334c220",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, y_val = preprocessor.sliding_windows(carla_llm, window_size=10, step_size=5)\n",
    "y_val = preprocessor.one_hot_encode(y_val, one_hot_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5a10f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model: XGBClassifier_{'colsample_bytree': 1.0, 'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 700, 'subsample': 0.5}\n",
    "params = {\n",
    "    'colsample_bytree': 1.0,    \n",
    "    'learning_rate': 0.3,\n",
    "    'max_depth': 5,\n",
    "    'n_estimators': 700,\n",
    "    'subsample': 0.5,\n",
    "}\n",
    "for i in range(n_trials):\n",
    "    results = create_and_train_model(xgb.XGBClassifier, params)\n",
    "    add_to_dict(TRTS, 'carla_llm', 'XGBClassifier', results, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb98c7c7",
   "metadata": {},
   "source": [
    "## Results table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ef0f537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             f1_score  accuracy    recall  precision          model  \\\n",
      "key                                                                   \n",
      "sumo_llm     0.542695  0.550501  0.550501   0.542056  XGBClassifier   \n",
      "sumo_fixed   0.502740  0.505795  0.505795   0.502700  XGBClassifier   \n",
      "carla_llm    0.499644  0.499753  0.499753   0.499766  XGBClassifier   \n",
      "carla_fixed  0.433191  0.586130  0.586130   0.343549  XGBClassifier   \n",
      "\n",
      "                                                        params  \n",
      "key                                                             \n",
      "sumo_llm     {'colsample_bytree': 1.0, 'learning_rate': 0.1...  \n",
      "sumo_fixed   {'colsample_bytree': 0.5, 'learning_rate': 0.1...  \n",
      "carla_llm    {'colsample_bytree': 1.0, 'learning_rate': 0.3...  \n",
      "carla_fixed  {'colsample_bytree': 1.0, 'learning_rate': 0.0...  \n",
      "\n",
      "sumo_fixed:\n",
      "  Model: XGBClassifier\n",
      "  F1 Score: 0.50 ± 0.00\n",
      "  Accuracy: 0.51 ± 0.00\n",
      "  Recall: 0.51 ± 0.00\n",
      "  Precision: 0.50 ± 0.00\n",
      "\n",
      "sumo_llm:\n",
      "  Model: XGBClassifier\n",
      "  F1 Score: 0.54 ± 0.00\n",
      "  Accuracy: 0.55 ± 0.00\n",
      "  Recall: 0.55 ± 0.00\n",
      "  Precision: 0.54 ± 0.00\n",
      "\n",
      "carla_fixed:\n",
      "  Model: XGBClassifier\n",
      "  F1 Score: 0.43 ± 0.00\n",
      "  Accuracy: 0.59 ± 0.00\n",
      "  Recall: 0.59 ± 0.00\n",
      "  Precision: 0.34 ± 0.00\n",
      "\n",
      "carla_llm:\n",
      "  Model: XGBClassifier\n",
      "  F1 Score: 0.50 ± 0.00\n",
      "  Accuracy: 0.50 ± 0.00\n",
      "  Recall: 0.50 ± 0.00\n",
      "  Precision: 0.50 ± 0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "save_results_to_csv(TRTS, 'TRTS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00bb44e",
   "metadata": {},
   "source": [
    "# Discriminative Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ea4a7b",
   "metadata": {},
   "source": [
    "We seek to understand how well a classifier can separate the real and the synthetic data to determine how indistiguishable they are.\n",
    "\n",
    "If the classifiers do not get good scores, that means the data is hardly distinguishable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f962b4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = {}\n",
    "n_trials = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4fb96798",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_uah_disc_sumo = uah_training[sumo_columns_to_keep].drop(columns=['label'])\n",
    "X_uah_disc_carla = uah_training[carla_columns_to_keep].drop(columns=['label'])\n",
    "y_uah_disc = np.zeros(len(X_uah_disc_carla)) # 0 for real data and 1 for synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a2c99c",
   "metadata": {},
   "source": [
    "## SUMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc959c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sumo_disc_fixed, y_sumo_disc_fixed = sumo_fixed.drop(columns=['label']), np.ones(len(sumo_fixed))\n",
    "X_sumo_disc_llm, y_sumo_disc_llm = sumo_llm.drop(columns=['label']), np.ones(len(sumo_llm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb75d026",
   "metadata": {},
   "source": [
    "### Fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b5635fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = pd.concat([X_sumo_disc_fixed, X_uah_disc_sumo], axis=0, ignore_index=True), np.concat([y_sumo_disc_fixed, y_uah_disc], axis=0)\n",
    "X.reset_index(drop=True, inplace=True)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4508209a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 1.0\n",
      "F1 Score: 1.0\n",
      "F1 Score: 1.0\n",
      "F1 Score: 1.0\n",
      "F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_trials):\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred_rf = rf.predict(X_val)\n",
    "    print(f\"F1 Score: {f1_score(y_val, y_pred_rf, average='weighted')}\")\n",
    "\n",
    "    add_to_dict(DS, 'sumo_fixed', 'RFClassifier', {\n",
    "        'f1_score': f1_score(y_val, y_pred_rf, average='weighted'),\n",
    "        'accuracy': accuracy_score(y_val, y_pred_rf),\n",
    "        'recall': recall_score(y_val, y_pred_rf, average='weighted'),\n",
    "        'precision': precision_score(y_val, y_pred_rf, average='weighted'),\n",
    "        'model': rf\n",
    "    }, params={'default'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdb944b",
   "metadata": {},
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2593281c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = pd.concat([X_sumo_disc_llm, X_uah_disc_sumo], axis=0, ignore_index=True), np.concat([y_sumo_disc_llm, y_uah_disc], axis=0)\n",
    "X.reset_index(drop=True, inplace=True)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f06eff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_trials):\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred_rf = rf.predict(X_val)\n",
    "\n",
    "    add_to_dict(DS, 'sumo_llm', 'RFClassifier', {\n",
    "        'f1_score': f1_score(y_val, y_pred_rf, average='weighted'),\n",
    "        'accuracy': accuracy_score(y_val, y_pred_rf),\n",
    "        'recall': recall_score(y_val, y_pred_rf, average='weighted'),\n",
    "        'precision': precision_score(y_val, y_pred_rf, average='weighted'),\n",
    "        'model': rf\n",
    "    }, params={'default'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc572b9",
   "metadata": {},
   "source": [
    "## CARLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d3d9e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_carla_disc_fixed, y_carla_disc_fixed = carla_fixed.drop(columns=['label']), np.ones(len(carla_fixed))\n",
    "X_carla_disc_llm, y_carla_disc_llm = carla_llm.drop(columns=['label']), np.ones(len(carla_llm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13c9d64",
   "metadata": {},
   "source": [
    "### Fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6fcc9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = pd.concat([X_carla_disc_fixed, X_uah_disc_carla], axis=0, ignore_index=True), np.concat([y_carla_disc_fixed, y_uah_disc], axis=0)\n",
    "X.reset_index(drop=True, inplace=True)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2169b82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_trials):\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred_rf = rf.predict(X_val)\n",
    "\n",
    "    add_to_dict(DS, 'carla_fixed', 'RFClassifier', {\n",
    "        'f1_score': f1_score(y_val, y_pred_rf, average='weighted'),\n",
    "        'accuracy': accuracy_score(y_val, y_pred_rf),\n",
    "        'recall': recall_score(y_val, y_pred_rf, average='weighted'),\n",
    "        'precision': precision_score(y_val, y_pred_rf, average='weighted'),\n",
    "        'model': rf\n",
    "    }, params={'default'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67f88f7",
   "metadata": {},
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa3c7d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = pd.concat([X_carla_disc_llm, X_uah_disc_carla], axis=0, ignore_index=True), np.concat([y_carla_disc_llm, y_uah_disc], axis=0)\n",
    "X.reset_index(drop=True, inplace=True)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca3c9f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_trials):\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred_rf = rf.predict(X_val)\n",
    "\n",
    "    add_to_dict(DS, 'carla_llm', 'RFClassifier', {\n",
    "        'f1_score': f1_score(y_val, y_pred_rf, average='weighted'),\n",
    "        'accuracy': accuracy_score(y_val, y_pred_rf),\n",
    "        'recall': recall_score(y_val, y_pred_rf, average='weighted'),\n",
    "        'precision': precision_score(y_val, y_pred_rf, average='weighted'),\n",
    "        'model': rf\n",
    "    }, params={'default'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0d7af1",
   "metadata": {},
   "source": [
    "## Results Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ea57c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             f1_score  accuracy  recall  precision         model     params\n",
      "key                                                                        \n",
      "sumo_fixed        1.0       1.0     1.0        1.0  RFClassifier  {default}\n",
      "sumo_llm          1.0       1.0     1.0        1.0  RFClassifier  {default}\n",
      "carla_fixed       1.0       1.0     1.0        1.0  RFClassifier  {default}\n",
      "carla_llm         1.0       1.0     1.0        1.0  RFClassifier  {default}\n",
      "\n",
      "sumo_fixed:\n",
      "  Model: RFClassifier\n",
      "  F1 Score: 1.00 ± 0.00\n",
      "  Accuracy: 1.00 ± 0.00\n",
      "  Recall: 1.00 ± 0.00\n",
      "  Precision: 1.00 ± 0.00\n",
      "\n",
      "sumo_llm:\n",
      "  Model: RFClassifier\n",
      "  F1 Score: 1.00 ± 0.00\n",
      "  Accuracy: 1.00 ± 0.00\n",
      "  Recall: 1.00 ± 0.00\n",
      "  Precision: 1.00 ± 0.00\n",
      "\n",
      "carla_fixed:\n",
      "  Model: RFClassifier\n",
      "  F1 Score: 1.00 ± 0.00\n",
      "  Accuracy: 1.00 ± 0.00\n",
      "  Recall: 1.00 ± 0.00\n",
      "  Precision: 1.00 ± 0.00\n",
      "\n",
      "carla_llm:\n",
      "  Model: RFClassifier\n",
      "  F1 Score: 1.00 ± 0.00\n",
      "  Accuracy: 1.00 ± 0.00\n",
      "  Recall: 1.00 ± 0.00\n",
      "  Precision: 1.00 ± 0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "save_results_to_csv(DS, 'DS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1d188d",
   "metadata": {},
   "source": [
    "# Predictive Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4ef45f",
   "metadata": {},
   "source": [
    "Here we train on different combinations of real and synthetic data and test on real data only in order to verify the quality of the data for real-world applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8530966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PS = {}\n",
    "n_trials = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f678a67",
   "metadata": {},
   "source": [
    "## Real Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05595ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z', 'angle', 'speed', 'label']\n",
    "\n",
    "X_train, y_train = preprocessor.sliding_windows(uah_training[columns_to_keep], window_size=window_size, step_size=step_size)\n",
    "X_val, y_val = preprocessor.sliding_windows(uah_validation[columns_to_keep], window_size=window_size, step_size=step_size)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "y_train = preprocessor.one_hot_encode(y_train, one_hot_keys=one_hot_keys)\n",
    "y_val = preprocessor.one_hot_encode(y_val, one_hot_keys=one_hot_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b6acdef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model: SVC_{'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
    "params = {\n",
    "    'C': 1,\n",
    "    'gamma': 0.01,\n",
    "    'kernel': 'rbf',\n",
    "}\n",
    "for i in range(n_trials):\n",
    "    results = create_and_train_model(SVC, params)\n",
    "    add_to_dict(PS, 'uah', 'SVC', results, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f0c899",
   "metadata": {},
   "source": [
    "## SUMO Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b0bd8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUMO\n",
    "X_sumo_fixed, y_sumo_fixed = preprocessor.sliding_windows(sumo_fixed, window_size=window_size, step_size=step_size)\n",
    "X_sumo_llm, y_sumo_llm = preprocessor.sliding_windows(sumo_llm, window_size=window_size, step_size=step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98105bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to keep for validation: ['acc', 'angle', 'speed', 'label']\n"
     ]
    }
   ],
   "source": [
    "# Getting the validation for SUMO variables\n",
    "print(\"Columns to keep for validation:\", sumo_columns_to_keep)\n",
    "\n",
    "X_val_base, y_val = preprocessor.sliding_windows(uah_validation[sumo_columns_to_keep], window_size=window_size, step_size=step_size)\n",
    "y_val = preprocessor.one_hot_encode(y_val, one_hot_keys=one_hot_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e823c8",
   "metadata": {},
   "source": [
    "### Fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f7026fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_sumo_fixed, y_sumo_fixed\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val_base)\n",
    "y_train = preprocessor.one_hot_encode(y_train, one_hot_keys=one_hot_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fafbfdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model: RandomForestClassifier_{'max_depth': 50, 'n_estimators': 100}\n",
    "params = {\n",
    "    'max_depth': 50,\n",
    "    'n_estimators': 100,\n",
    "}\n",
    "for i in range(n_trials):\n",
    "    results = create_and_train_model(RandomForestClassifier, params)\n",
    "    add_to_dict(PS, 'sumo_fixed', 'RFClassifier', results, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65285841",
   "metadata": {},
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0460281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_sumo_llm, y_sumo_llm\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val_base)\n",
    "y_train = preprocessor.one_hot_encode(y_train, one_hot_keys=one_hot_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "71ac4613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model: XGBClassifier_{'colsample_bytree': 1.0, 'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 500, 'subsample': 0.5}\n",
    "params = {\n",
    "    'colsample_bytree': 1.0,\n",
    "    'learning_rate': 0.2,\n",
    "    'max_depth': 5,\n",
    "    'n_estimators': 500,\n",
    "    'subsample': 0.5,\n",
    "}\n",
    "for i in range(n_trials):\n",
    "    results = create_and_train_model(xgb.XGBClassifier, params)\n",
    "    add_to_dict(PS, 'sumo_llm', 'XGBClassifier', results, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d562a57b",
   "metadata": {},
   "source": [
    "## Carla Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d0a613b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_carla_fixed, y_carla_fixed = preprocessor.sliding_windows(carla_fixed, window_size=window_size, step_size=step_size)\n",
    "X_carla_llm, y_carla_llm = preprocessor.sliding_windows(carla_llm, window_size=window_size, step_size=step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "40fa1c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to keep for validation: ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z', 'angle', 'label', 'acc']\n"
     ]
    }
   ],
   "source": [
    "# Getting the validation for SUMO variables\n",
    "print(\"Columns to keep for validation:\", carla_columns_to_keep)\n",
    "X_val_base, y_val = preprocessor.sliding_windows(uah_validation[carla_columns_to_keep], window_size=window_size, step_size=step_size)\n",
    "y_val = preprocessor.one_hot_encode(y_val, one_hot_keys=one_hot_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17def673",
   "metadata": {},
   "source": [
    "### Fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f460d11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_carla_fixed, y_carla_fixed\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val_base)\n",
    "y_train = preprocessor.one_hot_encode(y_train, one_hot_keys=one_hot_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "084f64cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model: RandomForestClassifier_{'max_depth': 10, 'n_estimators': 20}\n",
    "params = {\n",
    "    'max_depth': 10,\n",
    "    'n_estimators': 20,\n",
    "}\n",
    "for i in range(n_trials):\n",
    "    results = create_and_train_model(RandomForestClassifier, params)\n",
    "    add_to_dict(PS, 'carla_fixed', 'RFClassifier', results, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940416e1",
   "metadata": {},
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d8198c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_carla_llm, y_carla_llm\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val_base)\n",
    "y_train = preprocessor.one_hot_encode(y_train, one_hot_keys=one_hot_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4b449f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model: RandomForestClassifier_{'max_depth': 10, 'n_estimators': 20}\n",
    "params = {\n",
    "    'max_depth': 10,\n",
    "    'n_estimators': 20,\n",
    "}\n",
    "for i in range(n_trials):\n",
    "    results = create_and_train_model(RandomForestClassifier, params)\n",
    "    add_to_dict(PS, 'carla_llm', 'RFClassifier', results, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d17d697",
   "metadata": {},
   "source": [
    "## Real + SUMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "08cda850",
   "metadata": {},
   "outputs": [],
   "source": [
    "sumo_uah_fixed_20 = preprocessor.fill_synthetic_data(sumo_uah_fixed, 0.2)\n",
    "sumo_uah_llm_20 = preprocessor.fill_synthetic_data(sumo_uah_llm, 0.2)\n",
    "\n",
    "sumo_uah_fixed_60 = preprocessor.fill_synthetic_data(sumo_uah_fixed, 0.6)\n",
    "sumo_uah_llm_60 = preprocessor.fill_synthetic_data(sumo_uah_llm, 0.6)\n",
    "\n",
    "sumo_uah_fixed_100 = preprocessor.fill_synthetic_data(sumo_uah_fixed, 1)\n",
    "sumo_uah_llm_100 = preprocessor.fill_synthetic_data(sumo_uah_llm, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a60b0669",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sumo_uah_fixed_20, y_sumo_uah_fixed_20 = preprocessor.sliding_windows(sumo_uah_fixed_20, window_size=window_size, step_size=step_size)\n",
    "X_sumo_uah_llm_20, y_sumo_uah_llm_20 = preprocessor.sliding_windows(sumo_uah_llm_20, window_size=window_size, step_size=step_size)\n",
    "\n",
    "X_sumo_uah_fixed_60, y_sumo_uah_fixed_60 = preprocessor.sliding_windows(sumo_uah_fixed_60, window_size=window_size, step_size=step_size)\n",
    "X_sumo_uah_llm_60, y_sumo_uah_llm_60 = preprocessor.sliding_windows(sumo_uah_llm_60, window_size=window_size, step_size=step_size)\n",
    "\n",
    "X_sumo_uah_fixed_100, y_sumo_uah_fixed_100 = preprocessor.sliding_windows(sumo_uah_fixed_100, window_size=window_size, step_size=step_size)\n",
    "X_sumo_uah_llm_100, y_sumo_uah_llm_100 = preprocessor.sliding_windows(sumo_uah_llm_100, window_size=window_size, step_size=step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c6769432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to keep for validation: ['acc', 'angle', 'speed', 'label']\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns to keep for validation:\", sumo_columns_to_keep)\n",
    "\n",
    "X_val_base, y_val = preprocessor.sliding_windows(uah_validation[sumo_columns_to_keep], window_size=window_size, step_size=step_size)\n",
    "y_val = preprocessor.one_hot_encode(y_val, one_hot_keys=one_hot_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d285d9",
   "metadata": {},
   "source": [
    "## Real + SUMO (20%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133dd3c5",
   "metadata": {},
   "source": [
    "### Fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "43f2e1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_sumo_uah_fixed_20, y_sumo_uah_fixed_20\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val_base)\n",
    "y_train = preprocessor.one_hot_encode(y_train, one_hot_keys=one_hot_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c5b57a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model: XGBClassifier_{'colsample_bytree': 0.7, 'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 700, 'subsample': 0.5}\n",
    "params = {\n",
    "    'colsample_bytree': 0.7,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': None,\n",
    "    'n_estimators': 700,\n",
    "    'subsample': 0.5,\n",
    "}\n",
    "for i in range(n_trials):\n",
    "    results = create_and_train_model(xgb.XGBClassifier, params)\n",
    "    add_to_dict(PS, 'sumo_uah_fixed_20', 'XGBClassifier', results, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86358b9",
   "metadata": {},
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8e51b1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_sumo_uah_llm_20, y_sumo_uah_llm_20\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val_base)\n",
    "y_train = preprocessor.one_hot_encode(y_train, one_hot_keys=one_hot_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b46018d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model: RandomForestClassifier_{'max_depth': 10, 'n_estimators': 100}\n",
    "params = {\n",
    "    'max_depth': 10,\n",
    "    'n_estimators': 100,\n",
    "}\n",
    "for i in range(n_trials):\n",
    "    results = create_and_train_model(RandomForestClassifier, params)\n",
    "    add_to_dict(PS, 'sumo_uah_llm_20', 'RFClassifier', results, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c639de4",
   "metadata": {},
   "source": [
    "## Real + SUMO (60%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d9c9ec",
   "metadata": {},
   "source": [
    "### Fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ce15831d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_sumo_uah_fixed_60, y_sumo_uah_fixed_60\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val_base)\n",
    "y_train = preprocessor.one_hot_encode(y_train, one_hot_keys=one_hot_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eead5a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model: RandomForestClassifier_{'max_depth': 10, 'n_estimators': 100}\n",
    "params = {\n",
    "    'max_depth': 10,\n",
    "    'n_estimators': 100,\n",
    "}\n",
    "for i in range(n_trials):\n",
    "    results = create_and_train_model(RandomForestClassifier, params)\n",
    "    add_to_dict(PS, 'sumo_uah_fixed_60', 'RFClassifier', results, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cb9e0c",
   "metadata": {},
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c5a0b3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_sumo_uah_llm_60, y_sumo_uah_llm_60\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val_base)\n",
    "y_train = preprocessor.one_hot_encode(y_train, one_hot_keys=one_hot_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7ba5ac36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model: XGBClassifier_{'colsample_bytree': 1.0, 'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 1000, 'subsample': 0.7}\n",
    "params = {\n",
    "    'colsample_bytree': 1.0,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': None,\n",
    "    'n_estimators': 1000,\n",
    "    'subsample': 0.7,\n",
    "}\n",
    "for i in range(n_trials):\n",
    "    results = create_and_train_model(xgb.XGBClassifier, params)\n",
    "    add_to_dict(PS, 'sumo_uah_llm_60', 'XGBClassifier', results, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43efa6b6",
   "metadata": {},
   "source": [
    "## Real + SUMO (100%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdf5ec6",
   "metadata": {},
   "source": [
    "### Fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a05508a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_sumo_uah_fixed_100, y_sumo_uah_fixed_100\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val_base)\n",
    "y_train = preprocessor.one_hot_encode(y_train, one_hot_keys=one_hot_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "79031b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model: XGBClassifier_{'colsample_bytree': 1.0, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500, 'subsample': 0.5}\n",
    "params = {\n",
    "    'colsample_bytree': 1.0,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 10,\n",
    "    'n_estimators': 500,\n",
    "    'subsample': 0.5,\n",
    "}\n",
    "for i in range(n_trials):\n",
    "    results = create_and_train_model(xgb.XGBClassifier, params)\n",
    "    add_to_dict(PS, 'sumo_uah_fixed_100', 'XGBClassifier', results, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc17bfad",
   "metadata": {},
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cb449402",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_sumo_uah_llm_100, y_sumo_uah_llm_100\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val_base)\n",
    "y_train = preprocessor.one_hot_encode(y_train, one_hot_keys=one_hot_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a149f666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model: RandomForestClassifier_{'max_depth': 10, 'n_estimators': 100}\n",
    "params = {\n",
    "    'max_depth': 10,\n",
    "    'n_estimators': 100,\n",
    "}\n",
    "for i in range(n_trials):\n",
    "    results = create_and_train_model(RandomForestClassifier, params)\n",
    "    add_to_dict(PS, 'sumo_uah_llm_100', 'RandomForestClassifier', results, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10c56a9",
   "metadata": {},
   "source": [
    "## Real + CARLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ac4217a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "carla_uah_fixed_20 = preprocessor.fill_synthetic_data(carla_uah_fixed, 0.2)\n",
    "carla_uah_llm_20 = preprocessor.fill_synthetic_data(carla_uah_llm, 0.2)\n",
    "\n",
    "carla_uah_fixed_60 = preprocessor.fill_synthetic_data(carla_uah_fixed, 0.6)\n",
    "carla_uah_llm_60 = preprocessor.fill_synthetic_data(carla_uah_llm, 0.6)\n",
    "\n",
    "carla_uah_fixed_100 = preprocessor.fill_synthetic_data(carla_uah_fixed, 1)\n",
    "carla_uah_llm_100 = preprocessor.fill_synthetic_data(carla_uah_llm, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "891ede42",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_carla_uah_fixed_20, y_carla_uah_fixed_20 = preprocessor.sliding_windows(carla_uah_fixed_20, window_size=window_size, step_size=step_size)\n",
    "X_carla_uah_llm_20, y_carla_uah_llm_20 = preprocessor.sliding_windows(carla_uah_llm_20, window_size=window_size, step_size=step_size)\n",
    "\n",
    "X_carla_uah_fixed_60, y_carla_uah_fixed_60 = preprocessor.sliding_windows(carla_uah_fixed_60, window_size=window_size, step_size=step_size)\n",
    "X_carla_uah_llm_60, y_carla_uah_llm_60 = preprocessor.sliding_windows(carla_uah_llm_60, window_size=window_size, step_size=step_size)\n",
    "\n",
    "X_carla_uah_fixed_100, y_carla_uah_fixed_100 = preprocessor.sliding_windows(carla_uah_fixed_100, window_size=window_size, step_size=step_size)\n",
    "X_carla_uah_llm_100, y_carla_uah_llm_100 = preprocessor.sliding_windows(carla_uah_llm_100, window_size=window_size, step_size=step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5adc1ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to keep for validation: ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z', 'angle', 'label', 'acc']\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns to keep for validation:\", carla_columns_to_keep)\n",
    "\n",
    "X_val_base, y_val = preprocessor.sliding_windows(uah_validation[carla_columns_to_keep], window_size=window_size, step_size=step_size)\n",
    "y_val = preprocessor.one_hot_encode(y_val, one_hot_keys=one_hot_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dbf3c9",
   "metadata": {},
   "source": [
    "## Real + CARLA (20%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185dd9cd",
   "metadata": {},
   "source": [
    "### Fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "636373b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_carla_uah_fixed_20, y_carla_uah_fixed_20\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val_base)\n",
    "y_train = preprocessor.one_hot_encode(y_train, one_hot_keys=one_hot_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2d927a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model: XGBClassifier_{'colsample_bytree': 0.7, 'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 500, 'subsample': 0.5}\n",
    "params = {\n",
    "    'colsample_bytree': 0.7,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': None,\n",
    "    'n_estimators': 500,\n",
    "    'subsample': 0.5,\n",
    "}\n",
    "for i in range(n_trials):\n",
    "    results = create_and_train_model(xgb.XGBClassifier, params)\n",
    "    add_to_dict(PS, 'carla_uah_fixed_20', 'XGBClassifier', results, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7c7c69",
   "metadata": {},
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "61e34e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_carla_uah_llm_20, y_carla_uah_llm_20\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val_base)\n",
    "y_train = preprocessor.one_hot_encode(y_train, one_hot_keys=one_hot_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b941abc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model: XGBClassifier_{'colsample_bytree': 0.7, 'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 500, 'subsample': 0.5}\n",
    "params = {\n",
    "    'colsample_bytree': 0.7,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 5,\n",
    "    'n_estimators': 500,\n",
    "    'subsample': 0.5,\n",
    "}\n",
    "for i in range(n_trials):\n",
    "    results = create_and_train_model(xgb.XGBClassifier, params)\n",
    "    add_to_dict(PS, 'carla_uah_llm_20', 'XGBClassifier', results, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a2886a",
   "metadata": {},
   "source": [
    "## Real + CARLA (60%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d9ddfb",
   "metadata": {},
   "source": [
    "### Fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c1b7f372",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_carla_uah_fixed_60, y_carla_uah_fixed_60\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val_base)\n",
    "y_train = preprocessor.one_hot_encode(y_train, one_hot_keys=one_hot_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d85301f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model: RandomForestClassifier_{'max_depth': 50, 'n_estimators': 20}\n",
    "params = {\n",
    "    'max_depth': 50,\n",
    "    'n_estimators': 20,\n",
    "}\n",
    "for i in range(n_trials):\n",
    "    results = create_and_train_model(RandomForestClassifier, params)\n",
    "    add_to_dict(PS, 'carla_uah_fixed_60', 'RFClassifier', results, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1fe8a2",
   "metadata": {},
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "37800614",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_carla_uah_llm_60, y_carla_uah_llm_60\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val_base)\n",
    "y_train = preprocessor.one_hot_encode(y_train, one_hot_keys=one_hot_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "00a6977c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model: XGBClassifier_{'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 500, 'subsample': 1.0}\n",
    "params = {\n",
    "    'colsample_bytree': 0.5,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 5,\n",
    "    'n_estimators': 500,\n",
    "    'subsample': 1.0,\n",
    "}\n",
    "for i in range(n_trials):\n",
    "    results = create_and_train_model(xgb.XGBClassifier, params)\n",
    "    add_to_dict(PS, 'carla_uah_llm_60', 'XGBClassifier', results, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbd3157",
   "metadata": {},
   "source": [
    "## Real + CARLA (100%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d450501",
   "metadata": {},
   "source": [
    "### Fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2b4d2757",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_carla_uah_fixed_100, y_carla_uah_fixed_100\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val_base)\n",
    "y_train = preprocessor.one_hot_encode(y_train, one_hot_keys=one_hot_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5ec1be4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model: RandomForestClassifier_{'max_depth': 20, 'n_estimators': 100}\n",
    "params = {\n",
    "    'max_depth': 20,\n",
    "    'n_estimators': 100,\n",
    "}\n",
    "for i in range(n_trials):\n",
    "    results = create_and_train_model(RandomForestClassifier, params)\n",
    "    add_to_dict(PS, 'carla_uah_fixed_100', 'RFClassifier', results, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953ef358",
   "metadata": {},
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6ce88d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_carla_uah_llm_100, y_carla_uah_llm_100\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val_base)\n",
    "y_train = preprocessor.one_hot_encode(y_train, one_hot_keys=one_hot_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a3d162d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model: RandomForestClassifier_{'max_depth': None, 'n_estimators': 500}\n",
    "params = {\n",
    "    'max_depth': None,\n",
    "    'n_estimators': 500,\n",
    "}\n",
    "for i in range(n_trials):\n",
    "    results = create_and_train_model(RandomForestClassifier, params)\n",
    "    add_to_dict(PS, 'carla_uah_llm_100', 'RandomForestClassifier', results, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5b15dfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "PS_summary = {}\n",
    "for key, value in PS.items():\n",
    "    PS_summary[key] = {\n",
    "        'model': value['model'],\n",
    "        \n",
    "        'f1_score': np.mean(value['f1_scores']),\n",
    "        'accuracy': np.mean(value['accuracy']),\n",
    "        'recall': np.mean(value['recall']),\n",
    "        'precision': np.mean(value['precision']),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568acb57",
   "metadata": {},
   "source": [
    "## Results Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a0fe5f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     f1_score  accuracy    recall  precision  \\\n",
      "key                                                            \n",
      "uah                  0.788758  0.789402  0.789402   0.792941   \n",
      "sumo_uah_fixed_20    0.737091  0.737092  0.737092   0.737096   \n",
      "sumo_uah_llm_60      0.734102  0.734110  0.734110   0.734142   \n",
      "sumo_uah_fixed_100   0.732889  0.732891  0.732891   0.732896   \n",
      "sumo_uah_llm_20      0.731311  0.731739  0.731739   0.733201   \n",
      "sumo_uah_llm_100     0.730478  0.730926  0.730926   0.732446   \n",
      "sumo_uah_fixed_60    0.729843  0.730248  0.730248   0.731612   \n",
      "carla_uah_fixed_20   0.662020  0.668383  0.668383   0.682016   \n",
      "carla_uah_llm_20     0.658785  0.668790  0.668790   0.691110   \n",
      "carla_uah_llm_60     0.653733  0.664589  0.664589   0.688077   \n",
      "carla_uah_fixed_100  0.637813  0.638569  0.638569   0.639780   \n",
      "carla_uah_llm_100    0.628213  0.628252  0.628252   0.628306   \n",
      "carla_uah_fixed_60   0.606611  0.607298  0.607298   0.608150   \n",
      "carla_llm            0.441108  0.478994  0.478994   0.462639   \n",
      "sumo_llm             0.415974  0.489226  0.489226   0.478659   \n",
      "carla_fixed          0.375789  0.492868  0.492868   0.484015   \n",
      "sumo_fixed           0.336823  0.501474  0.501474   0.750420   \n",
      "\n",
      "                                      model  \\\n",
      "key                                           \n",
      "uah                                     SVC   \n",
      "sumo_uah_fixed_20             XGBClassifier   \n",
      "sumo_uah_llm_60               XGBClassifier   \n",
      "sumo_uah_fixed_100            XGBClassifier   \n",
      "sumo_uah_llm_20                RFClassifier   \n",
      "sumo_uah_llm_100     RandomForestClassifier   \n",
      "sumo_uah_fixed_60              RFClassifier   \n",
      "carla_uah_fixed_20            XGBClassifier   \n",
      "carla_uah_llm_20              XGBClassifier   \n",
      "carla_uah_llm_60              XGBClassifier   \n",
      "carla_uah_fixed_100            RFClassifier   \n",
      "carla_uah_llm_100    RandomForestClassifier   \n",
      "carla_uah_fixed_60             RFClassifier   \n",
      "carla_llm                      RFClassifier   \n",
      "sumo_llm                      XGBClassifier   \n",
      "carla_fixed                    RFClassifier   \n",
      "sumo_fixed                     RFClassifier   \n",
      "\n",
      "                                                                params  \n",
      "key                                                                     \n",
      "uah                           {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}  \n",
      "sumo_uah_fixed_20    {'colsample_bytree': 0.7, 'learning_rate': 0.0...  \n",
      "sumo_uah_llm_60      {'colsample_bytree': 1.0, 'learning_rate': 0.0...  \n",
      "sumo_uah_fixed_100   {'colsample_bytree': 1.0, 'learning_rate': 0.0...  \n",
      "sumo_uah_llm_20                 {'max_depth': 10, 'n_estimators': 100}  \n",
      "sumo_uah_llm_100                {'max_depth': 10, 'n_estimators': 100}  \n",
      "sumo_uah_fixed_60               {'max_depth': 10, 'n_estimators': 100}  \n",
      "carla_uah_fixed_20   {'colsample_bytree': 0.7, 'learning_rate': 0.0...  \n",
      "carla_uah_llm_20     {'colsample_bytree': 0.7, 'learning_rate': 0.0...  \n",
      "carla_uah_llm_60     {'colsample_bytree': 0.5, 'learning_rate': 0.0...  \n",
      "carla_uah_fixed_100             {'max_depth': 20, 'n_estimators': 100}  \n",
      "carla_uah_llm_100             {'max_depth': None, 'n_estimators': 500}  \n",
      "carla_uah_fixed_60               {'max_depth': 50, 'n_estimators': 20}  \n",
      "carla_llm                        {'max_depth': 10, 'n_estimators': 20}  \n",
      "sumo_llm             {'colsample_bytree': 1.0, 'learning_rate': 0.2...  \n",
      "carla_fixed                      {'max_depth': 10, 'n_estimators': 20}  \n",
      "sumo_fixed                      {'max_depth': 50, 'n_estimators': 100}  \n",
      "\n",
      "uah:\n",
      "  Model: SVC\n",
      "  F1 Score: 0.79 ± 0.00\n",
      "  Accuracy: 0.79 ± 0.00\n",
      "  Recall: 0.79 ± 0.00\n",
      "  Precision: 0.79 ± 0.00\n",
      "\n",
      "sumo_fixed:\n",
      "  Model: RFClassifier\n",
      "  F1 Score: 0.34 ± 0.00\n",
      "  Accuracy: 0.50 ± 0.00\n",
      "  Recall: 0.50 ± 0.00\n",
      "  Precision: 0.75 ± 0.00\n",
      "\n",
      "sumo_llm:\n",
      "  Model: XGBClassifier\n",
      "  F1 Score: 0.42 ± 0.00\n",
      "  Accuracy: 0.49 ± 0.00\n",
      "  Recall: 0.49 ± 0.00\n",
      "  Precision: 0.48 ± 0.00\n",
      "\n",
      "carla_fixed:\n",
      "  Model: RFClassifier\n",
      "  F1 Score: 0.38 ± 0.05\n",
      "  Accuracy: 0.49 ± 0.01\n",
      "  Recall: 0.49 ± 0.01\n",
      "  Precision: 0.48 ± 0.05\n",
      "\n",
      "carla_llm:\n",
      "  Model: RFClassifier\n",
      "  F1 Score: 0.44 ± 0.06\n",
      "  Accuracy: 0.48 ± 0.03\n",
      "  Recall: 0.48 ± 0.03\n",
      "  Precision: 0.46 ± 0.05\n",
      "\n",
      "sumo_uah_fixed_20:\n",
      "  Model: XGBClassifier\n",
      "  F1 Score: 0.74 ± 0.00\n",
      "  Accuracy: 0.74 ± 0.00\n",
      "  Recall: 0.74 ± 0.00\n",
      "  Precision: 0.74 ± 0.00\n",
      "\n",
      "sumo_uah_llm_20:\n",
      "  Model: RFClassifier\n",
      "  F1 Score: 0.73 ± 0.00\n",
      "  Accuracy: 0.73 ± 0.00\n",
      "  Recall: 0.73 ± 0.00\n",
      "  Precision: 0.73 ± 0.00\n",
      "\n",
      "sumo_uah_fixed_60:\n",
      "  Model: RFClassifier\n",
      "  F1 Score: 0.73 ± 0.00\n",
      "  Accuracy: 0.73 ± 0.00\n",
      "  Recall: 0.73 ± 0.00\n",
      "  Precision: 0.73 ± 0.00\n",
      "\n",
      "sumo_uah_llm_60:\n",
      "  Model: XGBClassifier\n",
      "  F1 Score: 0.73 ± 0.00\n",
      "  Accuracy: 0.73 ± 0.00\n",
      "  Recall: 0.73 ± 0.00\n",
      "  Precision: 0.73 ± 0.00\n",
      "\n",
      "sumo_uah_fixed_100:\n",
      "  Model: XGBClassifier\n",
      "  F1 Score: 0.73 ± 0.00\n",
      "  Accuracy: 0.73 ± 0.00\n",
      "  Recall: 0.73 ± 0.00\n",
      "  Precision: 0.73 ± 0.00\n",
      "\n",
      "sumo_uah_llm_100:\n",
      "  Model: RandomForestClassifier\n",
      "  F1 Score: 0.73 ± 0.00\n",
      "  Accuracy: 0.73 ± 0.00\n",
      "  Recall: 0.73 ± 0.00\n",
      "  Precision: 0.73 ± 0.00\n",
      "\n",
      "carla_uah_fixed_20:\n",
      "  Model: XGBClassifier\n",
      "  F1 Score: 0.66 ± 0.00\n",
      "  Accuracy: 0.67 ± 0.00\n",
      "  Recall: 0.67 ± 0.00\n",
      "  Precision: 0.68 ± 0.00\n",
      "\n",
      "carla_uah_llm_20:\n",
      "  Model: XGBClassifier\n",
      "  F1 Score: 0.66 ± 0.00\n",
      "  Accuracy: 0.67 ± 0.00\n",
      "  Recall: 0.67 ± 0.00\n",
      "  Precision: 0.69 ± 0.00\n",
      "\n",
      "carla_uah_fixed_60:\n",
      "  Model: RFClassifier\n",
      "  F1 Score: 0.61 ± 0.02\n",
      "  Accuracy: 0.61 ± 0.02\n",
      "  Recall: 0.61 ± 0.02\n",
      "  Precision: 0.61 ± 0.02\n",
      "\n",
      "carla_uah_llm_60:\n",
      "  Model: XGBClassifier\n",
      "  F1 Score: 0.65 ± 0.00\n",
      "  Accuracy: 0.66 ± 0.00\n",
      "  Recall: 0.66 ± 0.00\n",
      "  Precision: 0.69 ± 0.00\n",
      "\n",
      "carla_uah_fixed_100:\n",
      "  Model: RFClassifier\n",
      "  F1 Score: 0.64 ± 0.01\n",
      "  Accuracy: 0.64 ± 0.01\n",
      "  Recall: 0.64 ± 0.01\n",
      "  Precision: 0.64 ± 0.01\n",
      "\n",
      "carla_uah_llm_100:\n",
      "  Model: RandomForestClassifier\n",
      "  F1 Score: 0.63 ± 0.01\n",
      "  Accuracy: 0.63 ± 0.01\n",
      "  Recall: 0.63 ± 0.01\n",
      "  Precision: 0.63 ± 0.01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "save_results_to_csv(PS, 'PS')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
