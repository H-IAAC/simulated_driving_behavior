{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1de239e",
   "metadata": {},
   "source": [
    "This notebook is used to organize the experiments. If you just want the best models found, you can refer to the `3_model_training` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2af455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import mlflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mlflow.models import infer_signature\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score, log_loss\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "os.sys.path.append(os.path.abspath('../src'))\n",
    "from data import loader\n",
    "from data import preprocessor\n",
    "\n",
    "mapname = 'Town01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8dc66672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_train_model(model, args):\n",
    "    \"\"\"\n",
    "    Function to create and train a model with given parameters.\n",
    "\n",
    "    Args:\n",
    "        model: The model to be trained.\n",
    "        args: Arguments for training the model.\n",
    "\n",
    "    Returns:\n",
    "        result: The result of the training process.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    # Train model with current hyperparameters\n",
    "    md = model(**args)\n",
    "    md.fit(X_train, y_train)\n",
    "    # Predict on the validation set\n",
    "    y_pred = md.predict(X_val)\n",
    "    y_pred_proba = md.predict_proba(X_val)\n",
    "    # Log training results\n",
    "    result[\"f1_score\"] = f1_score(y_val, y_pred, average='weighted')\n",
    "    result[\"accuracy\"] = accuracy_score(y_val, y_pred)\n",
    "    result[\"recall\"] = recall_score(y_val, y_pred, average='weighted')\n",
    "    result[\"precision\"] = precision_score(y_val, y_pred, average='weighted')\n",
    "    result[\"log_loss\"] = log_loss(y_val, y_pred_proba)\n",
    "    result[\"model\"] = md\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2cf70def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    \"\"\"\n",
    "    Objective function for hyperparameter optimization.\n",
    "    This function will be called by Hyperopt for each trial.\n",
    "    \"\"\"\n",
    "    with mlflow.start_run(nested=True):\n",
    "        # Log hyperparameters being tested\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        # Train model with current hyperparameters\n",
    "        result = create_and_train_model(\n",
    "            model,\n",
    "            args=params\n",
    "        )\n",
    "\n",
    "        # Log training results\n",
    "        mlflow.log_metrics(\n",
    "            {\n",
    "                \"accuracy\": result[\"accuracy\"],\n",
    "                \"recall\": result[\"recall\"],\n",
    "                \"precision\": result[\"precision\"],\n",
    "                \"f1_score\": result[\"f1_score\"],\n",
    "                \"log_loss\": result[\"log_loss\"]\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Log the trained model\n",
    "        mlflow.sklearn.log_model(\n",
    "            result[\"model\"], name=model.__name__, signature=signature)\n",
    "\n",
    "        # Return loss for Hyperopt (it minimizes)\n",
    "        return {\"loss\": result[\"log_loss\"], \"status\": STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1c8c77ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(run_name, max_evals, search_space, data_name):\n",
    "    # Create or set experiment\n",
    "\n",
    "    print(\n",
    "        f\"This will run {max_evals} trials to find optimal hyperparameters...\")\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        # Log experiment metadata\n",
    "        mlflow.log_params(\n",
    "            {\n",
    "                \"optimization_method\": \"Tree-structured Parzen Estimator (TPE)\",\n",
    "                \"max_evaluations\": max_evals,\n",
    "                \"objective_metric\": \"log_loss\",\n",
    "                \"dataset\": data_name,\n",
    "                \"model_type\": model.__name__,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Run optimization\n",
    "        trials = Trials()\n",
    "        best_params = fmin(\n",
    "            fn=objective,\n",
    "            space=search_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=max_evals,\n",
    "            trials=trials,\n",
    "            verbose=True,\n",
    "        )\n",
    "        print(best_params)\n",
    "\n",
    "        # Find and log best results\n",
    "        best_trial = min(trials.results, key=lambda x: x[\"loss\"])\n",
    "        best_log_loss = best_trial[\"loss\"]\n",
    "\n",
    "        # Log optimization results\n",
    "        mlflow.log_params(best_params)\n",
    "        mlflow.log_metrics(\n",
    "            {\n",
    "                \"best_log_loss\": best_log_loss,\n",
    "                \"total_trials\": len(trials.trials),\n",
    "                \"optimization_completed\": 1,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return best_log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cb3963a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = mlflow.tracking.MlflowClient(\"http://127.0.0.1:8080\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7abae7f",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3bb894a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers = ['D1', 'D2', 'D3', 'D4', 'D5'] # List of drivers to load\n",
    "uah_data = loader.read_data(drivers, os.path.abspath('../data/base/UAH-DRIVESET-v1'))\n",
    "carla_data, sumo_data = loader.load_synthetic_data(os.path.abspath(f'../data/synthetic/{mapname}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f77ad45",
   "metadata": {},
   "source": [
    "Stacking the data from UAH, SUMO and CARLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265f53af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UAH \n",
    "X_normal, y_normal = preprocessor.sliding_windows(uah_data['acc']['normal'], 'normal', window_size=10, step_size=5)\n",
    "X_aggressive, y_aggressive = preprocessor.sliding_windows(uah_data['acc']['aggressive'], 'aggressive', window_size=10, step_size=5)\n",
    "X_uah, y_uah = np.vstack([X_normal, X_aggressive]), np.concat([y_snormal, y_aggressive])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20b47b3",
   "metadata": {},
   "source": [
    "Now let's set aside a portion of the UAH-driveset for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8156b043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUMO\n",
    "X_normal, y_normal = preprocessor.sliding_windows(sumo_data['fixed']['traffic']['normal'], 'normal', window_size=10, step_size=5)\n",
    "X_aggressive, y_aggressive = preprocessor.sliding_windows(sumo_data['fixed']['traffic']['aggressive'], 'aggressive', window_size=10, step_size=5)\n",
    "X_sumo_fixed, y_sumo_fixed = np.vstack([X_normal, X_aggressive]), np.concatenate([y_normal, y_aggressive])\n",
    "\n",
    "X_normal, y_normal = preprocessor.sliding_windows(sumo_data['llm']['traffic']['normal'], 'normal', window_size=10, step_size=5)\n",
    "X_aggressive, y_aggressive = preprocessor.sliding_windows(sumo_data['llm']['traffic']['aggressive'], 'aggressive', window_size=10, step_size=5)\n",
    "X_sumo_llm, y_sumo_llm = np.vstack([X_normal, X_aggressive]), np.concatenate([y_normal, y_aggressive])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1ba45379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARLA\n",
    "X_normal, y_normal = preprocessor.sliding_windows(carla_data['fixed']['traffic']['normal'], 'normal', window_size=10, step_size=5)\n",
    "X_aggressive, y_aggressive = preprocessor.sliding_windows(carla_data['fixed']['traffic']['aggressive'], 'aggressive', window_size=10, step_size=5)\n",
    "X_carla_fixed, y_carla_fixed = np.vstack([X_normal, X_aggressive]), np.concatenate([y_normal, y_aggressive])\n",
    "\n",
    "X_normal, y_normal = preprocessor.sliding_windows(carla_data['llm']['traffic']['normal'], 'normal', window_size=10, step_size=5)\n",
    "X_aggressive, y_aggressive = preprocessor.sliding_windows(carla_data['llm']['traffic']['aggressive'], 'aggressive', window_size=10, step_size=5)\n",
    "X_carla_llm, y_carla_llm = np.vstack([X_normal, X_aggressive]), np.concatenate([y_normal, y_aggressive])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b210c607",
   "metadata": {},
   "source": [
    "Defining the search space for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88856f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space_rf = {\n",
    "    \"n_estimators\": hp.choice(\"n_estimators\", [50, 100]),\n",
    "    \"max_depth\": hp.choice(\"max_depth\", [None, 10, 20]),\n",
    "    \"random_state\": 42,\n",
    "}\n",
    "search_space_svc = {\n",
    "    \"C\": hp.loguniform(\"C\", -3, 3),  # Regularization parameter\n",
    "    \"kernel\": hp.choice(\"kernel\", [\"linear\", \"rbf\", \"poly\"]),  # Kernel type\n",
    "    \"gamma\": hp.loguniform(\"gamma\", -3, 3),  # Kernel coefficient for 'rbf', 'poly', and 'sigmoid'\n",
    "    \"degree\": hp.choice(\"degree\", [2, 3, 4]),  # Degree of the polynomial kernel function ('poly')\n",
    "    \"random_state\": 42\n",
    "}\n",
    "search_space_xgb = {\n",
    "    \"n_estimators\": hp.choice(\"n_estimators\", [50, 100]),\n",
    "    \"max_depth\": hp.choice(\"max_depth\", [None, 10, 20]),\n",
    "    \"learning_rate\": hp.loguniform(\"learning_rate\", -3, 0),\n",
    "    \"subsample\": hp.uniform(\"subsample\", 0.5, 1.0),\n",
    "    \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.5, 1.0),\n",
    "    \"random_state\": 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f678a67",
   "metadata": {},
   "source": [
    "## Real Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bc3f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_uah, y_uah, test_size=0.2, random_state=42)\n",
    "signature = infer_signature(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1730251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide an Experiment description that will appear in the UI\n",
    "experiment_description = (\n",
    "    \"Experiment to train models on the UAH driveset.\"\n",
    ")\n",
    "\n",
    "# Provide searchable tags that define characteristics of the Runs that\n",
    "# will be in this Experiment\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"driver-behavior-prediction\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "}\n",
    "\n",
    "# Create the Experiment, providing a unique name\n",
    "driver_behavior_experiment = client.create_experiment(\n",
    "    name=\"Driver_Behavior_Models_UAH\", tags=experiment_tags\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05595ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/817421822837973294', creation_time=1753199157593, experiment_id='817421822837973294', last_update_time=1753199157593, lifecycle_stage='active', name='Driver_Behavior_Models_UAH', tags={'mlflow.note.content': 'Experiment to train models on the UAH driveset.',\n",
       " 'project_name': 'driver-behavior-prediction'}>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment('Driver_Behavior_Models_UAH')\n",
    "data_name = 'UAH-DRIVESET'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d095b905",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab04b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This will run 5 trials to find optimal hyperparameters...\n",
      "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run awesome-lamb-730 at: http://127.0.0.1:8080/#/experiments/817421822837973294/runs/45ed210f121d4c0e8cced9cd16489ae9\n",
      "\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:8080/#/experiments/817421822837973294\n",
      "\n",
      "ðŸƒ View run dazzling-mink-677 at: http://127.0.0.1:8080/#/experiments/817421822837973294/runs/2de27a0405484e5eb44c4a8645a93c0e\n",
      "\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:8080/#/experiments/817421822837973294   \n",
      "\n",
      "ðŸƒ View run loud-chimp-335 at: http://127.0.0.1:8080/#/experiments/817421822837973294/runs/c5866df714604558bc26c4421785d124\n",
      "\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:8080/#/experiments/817421822837973294   \n",
      "\n",
      "ðŸƒ View run inquisitive-loon-404 at: http://127.0.0.1:8080/#/experiments/817421822837973294/runs/f36b3141d6ab40ada1a8a25c318e202d\n",
      "\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:8080/#/experiments/817421822837973294   \n",
      "\n",
      "ðŸƒ View run beautiful-fox-651 at: http://127.0.0.1:8080/#/experiments/817421822837973294/runs/0842c87e13c547f69b84e5dcde5a8a72\n",
      "\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:8080/#/experiments/817421822837973294   \n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:51<00:00, 10.22s/trial, best loss: 0.10539734495751527]\n",
      "{'max_depth': np.int64(2), 'n_estimators': np.int64(0)}\n",
      "ðŸƒ View run rf-sweep at: http://127.0.0.1:8080/#/experiments/817421822837973294/runs/43a0bd24a0b540c7ae5527eb9b46781d\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:8080/#/experiments/817421822837973294\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier\n",
    "run_experiments('rf-sweep', max_evals=5, search_space=search_space_rf, data_name='UAH')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73b4851",
   "metadata": {},
   "source": [
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773fcdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC\n",
    "run_experiments('svc-sweep', max_evals=5, search_space=search_space_rf, data_name='UAH')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b75ca59",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a73e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier\n",
    "run_experiments('xgb-sweep', max_evals=5, search_space=search_space_xgb, data_name='UAH')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f0c899",
   "metadata": {},
   "source": [
    "## SUMO Only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d285d9",
   "metadata": {},
   "source": [
    "## Real + SUMO (fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8808584",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "signature = infer_signature(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5840afcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide an Experiment description that will appear in the UI\n",
    "experiment_description = (\n",
    "    \"Experiment to train models on the UAH driveset supplemented by SUMO with fixed parameters.\"\n",
    ")\n",
    "\n",
    "# Provide searchable tags that define characteristics of the Runs that\n",
    "# will be in this Experiment\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"driver-behavior-prediction\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "}\n",
    "\n",
    "# Create the Experiment, providing a unique name\n",
    "driver_behavior_experiment = client.create_experiment(\n",
    "    name=\"Driver_Behavior_Models_UAH_SUMO_fixed\", tags=experiment_tags\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb54c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier\n",
    "run_experiments('rf-sweep', max_evals=5, search_space=search_space_rf, data_name='UAH')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025c81b9",
   "metadata": {},
   "source": [
    "## Real + SUMO (LLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fd4ef5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
