{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1de239e",
   "metadata": {},
   "source": [
    "This notebook is used to organize the experiments. If you just want the best models found, you can refer to the `3_model_training` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "3e2af455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import mlflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mlflow.models import infer_signature\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score, log_loss\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "os.sys.path.append(os.path.abspath('../src'))\n",
    "from data import loader\n",
    "from data import preprocessor\n",
    "\n",
    "mapname = 'Town01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "8dc66672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_train_model(model, args):\n",
    "    \"\"\"\n",
    "    Function to create and train a model with given parameters.\n",
    "\n",
    "    Args:\n",
    "        model: The model to be trained.\n",
    "        args: Arguments for training the model.\n",
    "\n",
    "    Returns:\n",
    "        result: The result of the training process.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    # Train model with current hyperparameters\n",
    "    md = model(**args)\n",
    "    md.fit(X_train, y_train)\n",
    "    # Predict on the validation set\n",
    "    y_pred = md.predict(X_val)\n",
    "    y_pred_proba = md.predict_proba(X_val)\n",
    "    # Log training results\n",
    "    result[\"f1_score\"] = f1_score(y_val, y_pred, average='weighted')\n",
    "    result[\"accuracy\"] = accuracy_score(y_val, y_pred)\n",
    "    result[\"recall\"] = recall_score(y_val, y_pred, average='weighted')\n",
    "    result[\"precision\"] = precision_score(y_val, y_pred, average='weighted')\n",
    "    result[\"log_loss\"] = log_loss(y_val, y_pred_proba)\n",
    "    result[\"model\"] = md\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "2cf70def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    \"\"\"\n",
    "    Objective function for hyperparameter optimization.\n",
    "    This function will be called by Hyperopt for each trial.\n",
    "    \"\"\"\n",
    "    with mlflow.start_run(nested=True):\n",
    "        # Log hyperparameters being tested\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        # Train model with current hyperparameters\n",
    "        result = create_and_train_model(\n",
    "            model,\n",
    "            args=params\n",
    "        )\n",
    "\n",
    "        # Log training results\n",
    "        mlflow.log_metrics(\n",
    "            {\n",
    "                \"accuracy\": result[\"accuracy\"],\n",
    "                \"recall\": result[\"recall\"],\n",
    "                \"precision\": result[\"precision\"],\n",
    "                \"f1_score\": result[\"f1_score\"],\n",
    "                \"log_loss\": result[\"log_loss\"]\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Log the trained model\n",
    "        mlflow.sklearn.log_model(\n",
    "            result[\"model\"], name=model.__name__, signature=signature)\n",
    "\n",
    "        # Return loss for Hyperopt (it minimizes)\n",
    "        return {\"loss\": result[\"log_loss\"], \"status\": STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1c8c77ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(run_name, max_evals, search_space, data_name):\n",
    "    # Create or set experiment\n",
    "\n",
    "    print(\n",
    "        f\"This will run {max_evals} trials to find optimal hyperparameters...\")\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        # Log experiment metadata\n",
    "        mlflow.log_params(\n",
    "            {\n",
    "                \"optimization_method\": \"Tree-structured Parzen Estimator (TPE)\",\n",
    "                \"max_evaluations\": max_evals,\n",
    "                \"objective_metric\": \"log_loss\",\n",
    "                \"dataset\": data_name,\n",
    "                \"model_type\": model.__name__,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Run optimization\n",
    "        trials = Trials()\n",
    "        best_params = fmin(\n",
    "            fn=objective,\n",
    "            space=search_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=max_evals,\n",
    "            trials=trials,\n",
    "            verbose=True,\n",
    "        )\n",
    "        print(best_params)\n",
    "\n",
    "        # Find and log best results\n",
    "        best_trial = min(trials.results, key=lambda x: x[\"loss\"])\n",
    "        best_log_loss = best_trial[\"loss\"]\n",
    "\n",
    "        # Log optimization results\n",
    "        mlflow.log_params(best_params)\n",
    "        mlflow.log_metrics(\n",
    "            {\n",
    "                \"best_log_loss\": best_log_loss,\n",
    "                \"total_trials\": len(trials.trials),\n",
    "                \"optimization_completed\": 1,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return best_log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "cb3963a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = mlflow.tracking.MlflowClient(\"http://127.0.0.1:8080\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7abae7f",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "3bb894a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data'\n",
    "uah_training = pd.read_csv(f'{data_path}/base/training_set_uah.csv')\n",
    "uah_validation = pd.read_csv(f'{data_path}/base/validation_set_uah.csv')\n",
    "\n",
    "carla_fixed = pd.read_csv(f'{data_path}/merged/{mapname}/carla/carla_fixed.csv')\n",
    "carla_llm = pd.read_csv(f'{data_path}/merged/{mapname}/carla/carla_llm.csv')\n",
    "\n",
    "sumo_fixed = pd.read_csv(f'{data_path}/merged/{mapname}/sumo/sumo_fixed.csv')\n",
    "sumo_llm = pd.read_csv(f'{data_path}/merged/{mapname}/sumo/sumo_llm.csv')\n",
    "\n",
    "carla_uah_fixed = pd.read_csv(f'{data_path}/merged/{mapname}/carla_uah/carla_uah_fixed.csv')\n",
    "carla_uah_llm = pd.read_csv(f'{data_path}/merged/{mapname}/carla_uah/carla_uah_llm.csv')\n",
    "\n",
    "sumo_uah_fixed = pd.read_csv(f'{data_path}/merged/{mapname}/sumo_uah/sumo_uah_fixed.csv')\n",
    "sumo_uah_llm = pd.read_csv(f'{data_path}/merged/{mapname}/sumo_uah/sumo_uah_llm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f77ad45",
   "metadata": {},
   "source": [
    "Applying sliding windows to UAH, SUMO and CARLA full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "9c64695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 10\n",
    "step_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "265f53af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UAH \n",
    "X_uah, y_uah = preprocessor.sliding_windows(uah_training, window_size=window_size, step_size=step_size)\n",
    "X_val, y_val = preprocessor.sliding_windows(uah_validation, window_size=window_size, step_size=step_size)\n",
    "\n",
    "# SUMO\n",
    "X_sumo_fixed, y_sumo_fixed = preprocessor.sliding_windows(sumo_fixed, window_size=window_size, step_size=step_size)\n",
    "X_sumo_llm, y_sumo_llm = preprocessor.sliding_windows(sumo_llm, window_size=window_size, step_size=step_size)\n",
    "\n",
    "# CARLA\n",
    "X_carla_fixed, y_carla_fixed = preprocessor.sliding_windows(carla_fixed, window_size=window_size, step_size=step_size)\n",
    "X_carla_llm, y_carla_llm = preprocessor.sliding_windows(carla_llm, window_size=window_size, step_size=step_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b210c607",
   "metadata": {},
   "source": [
    "Defining the search space for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "d88856f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_evals = 10\n",
    "\n",
    "search_space_rf = {\n",
    "    \"n_estimators\": hp.choice(\"n_estimators\", [50, 100]),\n",
    "    \"max_depth\": hp.choice(\"max_depth\", [None, 10, 20]),\n",
    "    \"random_state\": 42,\n",
    "}\n",
    "search_space_svc = {\n",
    "    \"C\": hp.loguniform(\"C\", -3, 3),  # Regularization parameter\n",
    "    \"kernel\": hp.choice(\"kernel\", [\"linear\", \"rbf\", \"poly\"]),  # Kernel type\n",
    "    \"gamma\": hp.loguniform(\"gamma\", -3, 3),  # Kernel coefficient for 'rbf', 'poly', and 'sigmoid'\n",
    "    \"degree\": hp.choice(\"degree\", [2, 3, 4]),  # Degree of the polynomial kernel function ('poly')\n",
    "    \"random_state\": 42\n",
    "}\n",
    "search_space_xgb = {\n",
    "    \"n_estimators\": hp.choice(\"n_estimators\", [50, 100]),\n",
    "    \"max_depth\": hp.choice(\"max_depth\", [None, 10, 20]),\n",
    "    \"learning_rate\": hp.loguniform(\"learning_rate\", -3, 0),\n",
    "    \"subsample\": hp.uniform(\"subsample\", 0.5, 1.0),\n",
    "    \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.5, 1.0),\n",
    "    \"random_state\": 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f678a67",
   "metadata": {},
   "source": [
    "## Real Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "1730251d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment already exists: RESOURCE_ALREADY_EXISTS: Experiment 'Driver_Behavior_Models_UAH' already exists.\n"
     ]
    }
   ],
   "source": [
    "# Provide an Experiment description that will appear in the UI\n",
    "experiment_description = (\n",
    "    \"Experiment to train models on the UAH driveset.\"\n",
    ")\n",
    "\n",
    "# Provide searchable tags that define characteristics of the Runs that\n",
    "# will be in this Experiment\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"driver-behavior-prediction\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "}\n",
    "\n",
    "# Create the Experiment, providing a unique name\n",
    "try:\n",
    "    driver_behavior_experiment = client.create_experiment(\n",
    "        name=\"Driver_Behavior_Models_UAH\", tags=experiment_tags\n",
    "    )\n",
    "except mlflow.exceptions.RestException as e:\n",
    "    print(f\"Experiment already exists: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "05595ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_uah, y_uah\n",
    "signature = infer_signature(X_uah, y_uah)\n",
    "mlflow.set_experiment('Driver_Behavior_Models_UAH')\n",
    "data_name = 'UAH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab04b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This will run 10 trials to find optimal hyperparameters...\n",
      "🏃 View run secretive-fish-366 at: http://127.0.0.1:8080/#/experiments/817421822837973294/runs/3cd9daedce484383860a6d3ad35a822a\n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/817421822837973294\n",
      "\n",
      "🏃 View run aged-skunk-358 at: http://127.0.0.1:8080/#/experiments/817421822837973294/runs/8857907b698d4e71aa2b931d4cb6243c\n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/817421822837973294   \n",
      "\n",
      "🏃 View run brawny-cod-980 at: http://127.0.0.1:8080/#/experiments/817421822837973294/runs/ac7e83c8046c4a77bac29883c9617293\n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/817421822837973294   \n",
      "\n",
      "🏃 View run fortunate-stag-608 at: http://127.0.0.1:8080/#/experiments/817421822837973294/runs/3262b7932e6142beb08142bf834c2147\n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/817421822837973294   \n",
      "\n",
      "🏃 View run brawny-penguin-771 at: http://127.0.0.1:8080/#/experiments/817421822837973294/runs/4ebb3c679ae44ff5bcd145c3a07b7a8c\n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/817421822837973294   \n",
      "\n",
      "🏃 View run melodic-yak-126 at: http://127.0.0.1:8080/#/experiments/817421822837973294/runs/0bc96429501b46e0b3a5ea6c6bfb4375\n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/817421822837973294   \n",
      "\n",
      "🏃 View run industrious-hog-208 at: http://127.0.0.1:8080/#/experiments/817421822837973294/runs/e3100f5b1c6143cab910072309a83962\n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/817421822837973294   \n",
      "\n",
      "🏃 View run enthused-bee-699 at: http://127.0.0.1:8080/#/experiments/817421822837973294/runs/b2566ad491d641e997236ee857093125\n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/817421822837973294   \n",
      "\n",
      "🏃 View run likeable-midge-306 at: http://127.0.0.1:8080/#/experiments/817421822837973294/runs/5c1792a779a641508d29d29911226591\n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/817421822837973294   \n",
      "\n",
      "🏃 View run ambitious-rat-471 at: http://127.0.0.1:8080/#/experiments/817421822837973294/runs/7639ae40b7924088bb1bca81e6b891f4\n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/817421822837973294   \n",
      "\n",
      "100%|██████████| 10/10 [01:28<00:00,  8.82s/trial, best loss: 0.7016114048797041]\n",
      "{'max_depth': np.int64(1), 'n_estimators': np.int64(1)}\n",
      "🏃 View run rf-sweep at: http://127.0.0.1:8080/#/experiments/817421822837973294/runs/c982c8474f044545a9f4e04c63a87637\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/817421822837973294\n",
      "This will run 10 trials to find optimal hyperparameters...\n",
      "  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier\n",
    "run_experiments('rf-sweep', max_evals=max_evals, search_space=search_space_rf, data_name='UAH')\n",
    "model = SVC\n",
    "run_experiments('svc-sweep', max_evals=max_evals, search_space=search_space_svc, data_name='UAH')\n",
    "model = xgb.XGBClassifier\n",
    "run_experiments('xgb-sweep', max_evals=max_evals, search_space=search_space_xgb, data_name='UAH')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f0c899",
   "metadata": {},
   "source": [
    "## SUMO Only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e823c8",
   "metadata": {},
   "source": [
    "### Fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da934d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide an Experiment description that will appear in the UI\n",
    "experiment_description = (\n",
    "    \"Experiment to train models on the SUMO Fixed dataset.\"\n",
    ")\n",
    "\n",
    "# Provide searchable tags that define characteristics of the Runs that\n",
    "# will be in this Experiment\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"driver-behavior-prediction\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "}\n",
    "\n",
    "# Create the Experiment, providing a unique name\n",
    "try:\n",
    "    driver_behavior_experiment = client.create_experiment(\n",
    "        name=\"Driver_Behavior_Models_SUMO_Fixed\", tags=experiment_tags\n",
    "    )\n",
    "except mlflow.exceptions.RestException as e:\n",
    "    print(f\"Experiment already exists: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7026fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_sumo_fixed, y_sumo_fixed\n",
    "signature = infer_signature(X_uah, y_uah)\n",
    "mlflow.set_experiment('Driver_Behavior_Models_SUMO_Fixed')\n",
    "data_name = 'SUMO_Fixed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7080e63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier\n",
    "run_experiments('rf-sweep', max_evals=max_evals, search_space=search_space_rf, data_name=data_name)\n",
    "model = SVC\n",
    "run_experiments('svc-sweep', max_evals=max_evals, search_space=search_space_svc, data_name=data_name)\n",
    "model = xgb.XGBClassifier\n",
    "run_experiments('xgb-sweep', max_evals=max_evals, search_space=search_space_xgb, data_name=data_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65285841",
   "metadata": {},
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567d9f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide an Experiment description that will appear in the UI\n",
    "experiment_description = (\n",
    "    \"Experiment to train models on the SUMO LLM dataset.\"\n",
    ")\n",
    "\n",
    "# Provide searchable tags that define characteristics of the Runs that\n",
    "# will be in this Experiment\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"driver-behavior-prediction\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "}\n",
    "\n",
    "# Create the Experiment, providing a unique name\n",
    "try:\n",
    "    driver_behavior_experiment = client.create_experiment(\n",
    "        name=\"Driver_Behavior_Models_SUMO_LLM\", tags=experiment_tags\n",
    "    )\n",
    "except mlflow.exceptions.RestException as e:\n",
    "    print(f\"Experiment already exists: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0460281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_sumo_llm, y_sumo_llm\n",
    "mlflow.set_experiment('Driver_Behavior_Models_SUMO_LLM')\n",
    "data_name = 'SUMO_LLM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da017c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier\n",
    "run_experiments('rf-sweep', max_evals=max_evals, search_space=search_space_rf, data_name=data_name)\n",
    "model = SVC\n",
    "run_experiments('svc-sweep', max_evals=max_evals, search_space=search_space_svc, data_name=data_name)\n",
    "model = xgb.XGBClassifier\n",
    "run_experiments('xgb-sweep', max_evals=max_evals, search_space=search_space_xgb, data_name=data_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d562a57b",
   "metadata": {},
   "source": [
    "## Carla Only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17def673",
   "metadata": {},
   "source": [
    "### Fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5520a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide an Experiment description that will appear in the UI\n",
    "experiment_description = (\n",
    "    \"Experiment to train models on the CARLA Fixed dataset.\"\n",
    ")\n",
    "\n",
    "# Provide searchable tags that define characteristics of the Runs that\n",
    "# will be in this Experiment\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"driver-behavior-prediction\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "}\n",
    "\n",
    "# Create the Experiment, providing a unique name\n",
    "try:\n",
    "    driver_behavior_experiment = client.create_experiment(\n",
    "        name=\"Driver_Behavior_Models_CARLA_Fixed\", tags=experiment_tags\n",
    "    )\n",
    "except mlflow.exceptions.RestException as e:\n",
    "    print(f\"Experiment already exists: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f460d11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_carla_fixed, y_carla_fixed\n",
    "mlflow.set_experiment('Driver_Behavior_Models_CARLA_Fixed')\n",
    "data_name = 'CARLA_Fixed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6740e674",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier\n",
    "run_experiments('rf-sweep', max_evals=max_evals, search_space=search_space_rf, data_name=data_name)\n",
    "model = SVC\n",
    "run_experiments('svc-sweep', max_evals=max_evals, search_space=search_space_svc, data_name=data_name)\n",
    "model = xgb.XGBClassifier\n",
    "run_experiments('xgb-sweep', max_evals=max_evals, search_space=search_space_xgb, data_name=data_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940416e1",
   "metadata": {},
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfd8115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide an Experiment description that will appear in the UI\n",
    "experiment_description = (\n",
    "    \"Experiment to train models on the CARLA LLM dataset.\"\n",
    ")\n",
    "\n",
    "# Provide searchable tags that define characteristics of the Runs that\n",
    "# will be in this Experiment\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"driver-behavior-prediction\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "}\n",
    "\n",
    "# Create the Experiment, providing a unique name\n",
    "try:\n",
    "    driver_behavior_experiment = client.create_experiment(\n",
    "        name=\"Driver_Behavior_Models_CARLA_LLM\", tags=experiment_tags\n",
    "    )\n",
    "except mlflow.exceptions.RestException as e:\n",
    "    print(f\"Experiment already exists: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8198c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_carla_llm, y_carla_llm\n",
    "mlflow.set_experiment('Driver_Behavior_Models_CARLA_LLM')\n",
    "data_name = 'CARLA_LLM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1a7997",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier\n",
    "run_experiments('rf-sweep', max_evals=max_evals, search_space=search_space_rf, data_name=data_name)\n",
    "model = SVC\n",
    "run_experiments('svc-sweep', max_evals=max_evals, search_space=search_space_svc, data_name=data_name)\n",
    "model = xgb.XGBClassifier\n",
    "run_experiments('xgb-sweep', max_evals=max_evals, search_space=search_space_xgb, data_name=data_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d285d9",
   "metadata": {},
   "source": [
    "## Real + SUMO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133dd3c5",
   "metadata": {},
   "source": [
    "### Fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c8808584",
   "metadata": {},
   "outputs": [],
   "source": [
    "signature = infer_signature(X_sumo_fixed, y_sumo_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5840afcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide an Experiment description that will appear in the UI\n",
    "experiment_description = (\n",
    "    \"Experiment to train models on the UAH driveset supplemented by SUMO with fixed parameters.\"\n",
    ")\n",
    "\n",
    "# Provide searchable tags that define characteristics of the Runs that\n",
    "# will be in this Experiment\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"driver-behavior-prediction\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "}\n",
    "\n",
    "# Create the Experiment, providing a unique name\n",
    "driver_behavior_experiment = client.create_experiment(\n",
    "    name=\"Driver_Behavior_Models_UAH_SUMO_fixed\", tags=experiment_tags\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb54c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier\n",
    "run_experiments('rf-sweep', max_evals=5, search_space=search_space_rf, data_name='UAH')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025c81b9",
   "metadata": {},
   "source": [
    "## Real + SUMO (LLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fd4ef5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
